<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>The MaaS Stack: Architecture Deep Dive :: Models as a Service (MaaS) on Red Hat OpenShift AI 3.x</title>
    <link rel="prev" href="section1.html">
    <link rel="next" href="section3.html">
    <meta name="description" content="A technical breakdown of the OpenShift AI 3.x MaaS stack, including vLLM, Gateway API, KEDA, and TrustyAI.">
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">Models as a Service (MaaS) on Red Hat OpenShift AI 3.x</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/REPLACEREPONAME/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="rhoai3-maas" data-version="3.2">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">Models as a Service (MaaS) on Red Hat OpenShift AI 3.x</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../index.html">Introduction &amp; Value</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="section1.html">Strategy Guide (Well-Lit Paths)</a>
  </li>
  <li class="nav-item is-current-page" data-depth="1">
    <a class="nav-link" href="section2.html">Taxonomy &amp; Reference</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="section3.html">Architecture Deep Dive</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="section4.html">Hands-On Lab</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="quiz.html">Quiz</a>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Models as a Service (MaaS) on Red Hat OpenShift AI 3.x</span>
    <span class="version">3.2</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">Models as a Service (MaaS) on Red Hat OpenShift AI 3.x</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">3.2</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">Models as a Service (MaaS) on Red Hat OpenShift AI 3.x</a></li>
    <li><a href="section2.html">Taxonomy &amp; Reference</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">The MaaS Stack: Architecture Deep Dive</h1>
<div id="preamble">
<div class="sectionbody">
<div class="paragraph lead">
<p>You have chosen the MaaS utility path. Now, let&#8217;s look at the blueprint.</p>
</div>
<div class="paragraph">
<p>To run AI as an industrialized service, you need more than just a container. You need a stack that handles <strong>inference</strong>, <strong>routing</strong>, <strong>governance</strong>, and <strong>observability</strong>.</p>
</div>
<div class="paragraph">
<p>This section breaks down the "MaaS Stack" layer by layer, showing how Red Hat OpenShift AI 3.x orchestrates these components to deliver a secure, scalable API.</p>
</div>
<div class="imageblock unresolved">
<div class="content">
<img src="maas-architecture-stack.png" alt="Diagram showing the 4 layers: Hardware &#8594; Inference (vLLM) &#8594; Networking (Gateway) &#8594; Governance (Kuadrant/TrustyAI)">
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_layer_1_the_inference_engine_vllm"><a class="anchor" href="#_layer_1_the_inference_engine_vllm"></a>Layer 1: The Inference Engine (vLLM)</h2>
<div class="sectionbody">
<div class="paragraph">
<p>At the heart of the stack is <strong>vLLM</strong>, the high-performance serving runtime.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Role:</strong> It loads the model weights and executes the neural network forward pass.</p>
</li>
<li>
<p><strong>Key Feature:</strong> <strong>PagedAttention</strong>. Unlike legacy runtimes that fragment memory, vLLM manages GPU memory like an operating system manages RAM (using pages). This allows for higher batch sizes and throughput.</p>
</li>
<li>
<p><strong>Deployment:</strong> vLLM runs as a standard Pod, but in a MaaS configuration, it is often deployed via the <strong>Service Mesh</strong> or <strong>Serverless</strong> components to support scale-to-zero.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_layer_2_role_oriented_networking_gateway_api"><a class="anchor" href="#_layer_2_role_oriented_networking_gateway_api"></a>Layer 2: Role-Oriented Networking (Gateway API)</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In RHOAI 3.x, we move away from simple OpenShift Routes to the <strong>Kubernetes Gateway API</strong>. This splits the responsibility of "exposing the service" into two distinct roles:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>The Infrastructure Architect</strong> manages the <strong>Gateway</strong>.</p>
<div class="ulist">
<ul>
<li>
<p>They define the "Front Door" (IP address, TLS certificates, load balancer hardware).</p>
</li>
<li>
<p><strong>Manifest:</strong> <code>Gateway</code></p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>The ML Engineer</strong> manages the <strong>HTTPRoute</strong>.</p>
<div class="ulist">
<ul>
<li>
<p>They simply "attach" their model to the Gateway.</p>
</li>
<li>
<p><strong>Manifest:</strong> <code>HTTPRoute</code> (e.g., "Route traffic from <code>api.corp.com/v1/models/llama-3</code> to my vLLM service").</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="title">Why this matters</div>
<div class="paragraph">
<p>This separation means developers can deploy new models without needing cluster-admin privileges to configure ingress controllers. It is the technical enabler of "Self-Service."</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_layer_3_the_governance_plane_kuadrant"><a class="anchor" href="#_layer_3_the_governance_plane_kuadrant"></a>Layer 3: The Governance Plane (Kuadrant)</h2>
<div class="sectionbody">
<div class="paragraph">
<p>An industrialized factory needs a foreman to ensure safety and efficiency. <strong>Kuadrant</strong> is that foreman.</p>
</div>
<div class="paragraph">
<p>It connects to the Gateway API to enforce policies <strong>before</strong> traffic hits the expensive GPUs.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Rate Limiting:</strong> Protects the system from being overwhelmed by a single user.</p>
</li>
<li>
<p><strong>Token-Awareness:</strong> This is critical for LLMs. A request with 10 tokens costs less than a request with 10,000 tokens. Kuadrant can rate-limit based on the <strong>aggregate token count</strong>, ensuring true cost control.</p>
</li>
<li>
<p><strong>AuthN/AuthZ:</strong> Integrates with <strong>Authorino</strong> to enforce OIDC authentication (Keycloak, Entra ID) at the edge.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_layer_4_observability_trust_trustyai"><a class="anchor" href="#_layer_4_observability_trust_trustyai"></a>Layer 4: Observability &amp; Trust (TrustyAI)</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The final layer ensures the factory is producing quality goods. <strong>TrustyAI</strong> monitors the model&#8217;s behavior in real-time.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Bias Detection:</strong> Is the model showing statistical bias against protected groups in its output?</p>
</li>
<li>
<p><strong>Drift Detection:</strong> Is the incoming data significantly different from the training data? (e.g., users asking about 2024 events when the model was trained on 2022 data).</p>
</li>
<li>
<p><strong>Explainability:</strong> Providing insights into <strong>why</strong> a model gave a specific response.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_scaling_logic_keda"><a class="anchor" href="#_scaling_logic_keda"></a>Scaling Logic: KEDA</h2>
<div class="sectionbody">
<div class="paragraph">
<p>How do we handle a burst of traffic? We don&#8217;t just look at CPU usage.</p>
</div>
<div class="paragraph">
<p><strong>KEDA (Kubernetes Event-Driven Autoscaling)</strong> scales the vLLM pods based on "application intelligence."</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>The Old Way (HPA):</strong> Scale when CPU &gt; 80%. (Too slow for AI; the queue is already full).</p>
</li>
<li>
<p><strong>The MaaS Way (KEDA):</strong> Scale when <code>serving_queue_depth &gt; 5</code>.</p>
</li>
<li>
<p><strong>Result:</strong> The system spins up new pods <strong>before</strong> latency degrades, ensuring a consistent <strong>Time-To-First-Token (TTFT)</strong>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_summary_the_request_lifecycle"><a class="anchor" href="#_summary_the_request_lifecycle"></a>Summary: The Request Lifecycle</h2>
<div class="sectionbody">
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>User</strong> sends a curl request to <code>api.corp.com</code>.</p>
</li>
<li>
<p><strong>Gateway</strong> receives the traffic.</p>
</li>
<li>
<p><strong>Kuadrant</strong> checks: "Does this user have quota remaining?" (If no &#8594; 429 Error).</p>
</li>
<li>
<p><strong>KEDA</strong> checks: "Is the queue too deep?" (If yes &#8594; Spin up more pods).</p>
</li>
<li>
<p><strong>vLLM</strong> processes the request using PagedAttention.</p>
</li>
<li>
<p><strong>TrustyAI</strong> asynchronously logs the input/output for bias analysis.</p>
</li>
<li>
<p><strong>Response</strong> is streamed back to the user.</p>
</li>
</ol>
</div>
<div class="paragraph text-center">
<p><strong>You have the blueprints. Now, let&#8217;s build the factory.</strong><br>
<a href="lab-setup.html"><strong>Next: Hands-On Lab - Deploying Your First MaaS Endpoint &gt;</strong></a></p>
</div>
</div>
</div>
<nav class="pagination">
  <span class="prev"><a href="section1.html">Strategy Guide (Well-Lit Paths)</a></span>
  <span class="next"><a href="section3.html">Architecture Deep Dive</a></span>
</nav>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
